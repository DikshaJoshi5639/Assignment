import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import skew, kurtosis, chi2_contingency, zscore
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import davies_bouldin_score

customers = pd.read_csv('Customers.csv')
products = pd.read_csv('Products.csv')
transactions = pd.read_csv('Transactions.csv')

print(customers.info())
print(products.info())
print(transactions.info())

print("\nSummary statistics for Customers dataset:")
print(customers.describe())

print("\nSummary statistics for Products dataset:")
print(products.describe())

print("\nSummary statistics for Transactions dataset:")
print(transactions.describe())

print("Missing values in datasets:")
print(customers.isnull().sum())
print(products.isnull().sum())
print(transactions.isnull().sum())

customers['SignupDate'] = pd.to_datetime(customers['SignupDate'])
transactions['TransactionDate'] = pd.to_datetime(transactions['TransactionDate'])

# EDA: Customer distribution by region
plt.figure(figsize=(8, 5))
sns.countplot(x='Region', data=customers, palette='viridis')
plt.title('Customer Distribution by Region')
plt.xlabel('Region')
plt.ylabel('Number of Customers')
plt.show()

# EDA: Top-selling products
top_products = transactions.groupby('ProductID')['Quantity'].sum().reset_index()
top_products = pd.merge(top_products, products, on='ProductID')
top_products = top_products.sort_values(by='Quantity', ascending=False).head(10)

plt.figure(figsize=(10, 6))
sns.barplot(x='Quantity', y='ProductName', data=top_products, palette='coolwarm')
plt.title('Top 10 Best-Selling Products')
plt.xlabel('Quantity Sold')
plt.ylabel('Product Name')
plt.show()

# EDA: Sales trends over time
sales_trend = transactions.groupby('TransactionDate')['TotalValue'].sum().reset_index()

plt.figure(figsize=(12, 6))
plt.plot(sales_trend['TransactionDate'], sales_trend['TotalValue'], marker='o', color='b')
plt.title('Sales Trend Over Time')
plt.xlabel('Transaction Date')
plt.ylabel('Total Revenue')
plt.grid(True)
plt.show()

# EDA: Revenue by product category
category_revenue = pd.merge(transactions, products, on='ProductID')
category_revenue = category_revenue.groupby('Category')['TotalValue'].sum().reset_index()

plt.figure(figsize=(8, 5))
sns.barplot(x='TotalValue', y='Category', data=category_revenue, palette='magma')
plt.title('Revenue by Product Category')
plt.xlabel('Total Revenue')
plt.ylabel('Category')
plt.show()

# EDA: Top customers by lifetime value
top_customers = transactions.groupby('CustomerID')['TotalValue'].sum().reset_index()
top_customers = pd.merge(top_customers, customers, on='CustomerID')
top_customers = top_customers.sort_values(by='TotalValue', ascending=False).head(10)

plt.figure(figsize=(10, 6))
sns.barplot(x='TotalValue', y='CustomerName', data=top_customers, palette='Blues_d')
plt.title('Top 10 Customers by Lifetime Value')
plt.xlabel('Total Spending (USD)')
plt.ylabel('Customer Name')
plt.show()

# Merge data for additional analysis
data = pd.merge(transactions, products, on='ProductID')
data = pd.merge(data, customers, on='CustomerID')

def calculate_parameters(data, column):
    stats = {
        'Mean': data[column].mean(),
        'Median': data[column].median(),
        'Mode': data[column].mode()[0],
        'Standard Deviation': data[column].std(),
        'Variance': data[column].var(),
        'Range': data[column].max() - data[column].min(),
        'IQR': np.percentile(data[column], 75) - np.percentile(data[column], 25),
        'Skewness': skew(data[column]),
        'Kurtosis': kurtosis(data[column])
    }
    return stats

if 'TotalValue' in data.columns:
    total_value_stats = calculate_parameters(data, 'TotalValue')
    print("TotalValue Statistics:")
    for k, v in total_value_stats.items():
        print(f"{k}: {v}")

# ---- Correlation Matrix ----
if set(['Quantity', 'TotalValue']).issubset(data.columns):
    correlation_matrix = data[['Quantity', 'TotalValue']].corr()
    print("\nCorrelation Matrix:")
    print(correlation_matrix)

    # Heatmap Visualization
    plt.figure(figsize=(8, 6))
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')
    plt.title('Correlation Matrix Heatmap')
    plt.show()

# ---- Z-Score Calculation ----
data['Z-Score_TotalValue'] = zscore(data['TotalValue'])
print("\nSample Z-Scores for TotalValue:")
print(data[['CustomerID', 'TotalValue', 'Z-Score_TotalValue']].head())

# ---- Chi-square Test ----
if 'Category' in data.columns and 'Region' in data.columns:
    contingency_table = pd.crosstab(data['Category'], data['Region'])
    chi2, p, dof, expected = chi2_contingency(contingency_table)
    print("\nChi-square Test:")
    print(f"Chi2 Value: {chi2}, P-value: {p}")

plt.figure(figsize=(8, 5))
sns.histplot(data['TotalValue'], kde=True, bins=20, color='blue')
plt.title('Histogram of TotalValue')
plt.xlabel('TotalValue')
plt.ylabel('Frequency')
plt.show()

plt.figure(figsize=(8, 5))
sns.boxplot(x='Category', y='TotalValue', data=data, palette='Set2')
plt.title('Boxplot: TotalValue by Category')
plt.xlabel('Category')
plt.ylabel('TotalValue')
plt.show()

# Scatter Plot
plt.figure(figsize=(8, 5))
sns.scatterplot(x='Quantity', y='TotalValue', hue='Category', data=data, palette='viridis')
plt.title('Scatter Plot: Quantity vs TotalValue')
plt.xlabel('Quantity')
plt.ylabel('TotalValue')
plt.show()

# KMeans Clustering
customer_features = data.groupby('CustomerID').agg({
    'TotalValue': 'sum',
    'Quantity': 'sum'
}).reset_index()

scaler = StandardScaler()
scaled_features = scaler.fit_transform(customer_features[['TotalValue', 'Quantity']])

kmeans = KMeans(n_clusters=5, random_state=42)
customer_features['Cluster'] = kmeans.fit_predict(scaled_features)

db_index = davies_bouldin_score(scaled_features, customer_features['Cluster'])
print(f"Davies-Bouldin Index: {db_index:.2f}")

plt.figure(figsize=(10, 6))
sns.scatterplot(x=scaled_features[:, 0], y=scaled_features[:, 1], hue=customer_features['Cluster'], palette='viridis')
plt.title('Customer Clusters')
plt.xlabel('TotalValue (Scaled)')
plt.ylabel('Quantity (Scaled)')
plt.legend(title='Cluster')
plt.show()

# Save clustering results
customer_features.to_csv('Customer_Clusters.csv', index=False)
print("'Customer_Clusters.csv' saved successfully.")

# Save summary statistics
stats_df = pd.DataFrame.from_dict(total_value_stats, orient='index', columns=['Value'])
stats_df.to_csv('Summary_Statistics.csv', index=True)
print("Summary statistics saved to 'Summary_Statistics.csv'")
